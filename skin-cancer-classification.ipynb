{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3376422,"sourceType":"datasetVersion","datasetId":2035877}],"dockerImageVersionId":30579,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D\nimport numpy as np\nfrom tensorflow.keras.preprocessing import image\nimport time","metadata":{"execution":{"iopub.status.busy":"2024-02-11T17:35:42.939260Z","iopub.execute_input":"2024-02-11T17:35:42.939512Z","iopub.status.idle":"2024-02-11T17:36:01.061524Z","shell.execute_reply.started":"2024-02-11T17:35:42.939487Z","shell.execute_reply":"2024-02-11T17:36:01.060539Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"class myCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs={}):\n    if(logs.get('val_accuracy')>0.95):\n      print(\"\\nReached 95% accuracy so cancelling training!\")\n      self.model.stop_training = True","metadata":{"execution":{"iopub.status.busy":"2024-02-11T17:36:10.114094Z","iopub.execute_input":"2024-02-11T17:36:10.115245Z","iopub.status.idle":"2024-02-11T17:36:10.120555Z","shell.execute_reply.started":"2024-02-11T17:36:10.115206Z","shell.execute_reply":"2024-02-11T17:36:10.119658Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\n\n# # Define EarlyStopping callback\n# es = EarlyStopping(\n    \n#     monitor='val_loss',   # Monitor validation loss\n#     mode= 'min', \n#     patience=5, # Number of epochs with no improvement before stopping\n#     verbose=1,\n#     restore_best_weights=True  # Restore model weights to the best achieved during training\n# )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport os\nimport zipfile\n\n\n\n\n\ntrain_datagen = ImageDataGenerator(rescale = 1./255.,\n                                     rotation_range = 40,\n                                     width_shift_range = 0.2,\n                                     height_shift_range = 0.2,\n                                     shear_range = 0.2,\n                                     zoom_range = 0.2,\n                                     horizontal_flip = True\n                                   \n                                   )\n\n# Note that the validation data should not be augmented!\ntest_datagen = ImageDataGenerator( rescale = 1.0/255. )\n\n# Flow training images in batches of 20 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory('/kaggle/input/melanoma-skin-cancer-dataset-of-10000-images/melanoma_cancer_dataset/train',\n                                                    batch_size = 32,\n                                                    class_mode = 'binary', \n                                                    target_size = (120,120))     \n\n# Flow validation images in batches of 20 using test_datagen generator\nvalidation_generator =  test_datagen.flow_from_directory( '/kaggle/input/melanoma-skin-cancer-dataset-of-10000-images/melanoma_cancer_dataset/test',\n                                                          batch_size  = 32,\n                                                          class_mode  = 'binary', \n                                                          target_size = (120,120),\n                                                          shuffle = False \n                                                    )","metadata":{"execution":{"iopub.status.busy":"2024-02-11T17:36:13.884265Z","iopub.execute_input":"2024-02-11T17:36:13.884639Z","iopub.status.idle":"2024-02-11T17:36:30.724866Z","shell.execute_reply.started":"2024-02-11T17:36:13.884606Z","shell.execute_reply":"2024-02-11T17:36:30.724177Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Found 9605 images belonging to 2 classes.\nFound 1000 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# import tensorflow as tf\n\n# model = tf.keras.models.Sequential([\n#     # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n#     # This is the first convolution\n#     tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3),name=\"L1\"),\n#     tf.keras.layers.MaxPooling2D(2, 2),\n#     # The second convolution\n#     tf.keras.layers.Conv2D(64, (3,3), activation='relu',name=\"L2\"),\n#     tf.keras.layers.MaxPooling2D(2,2),\n#     # The third convolution\n#     tf.keras.layers.Conv2D(128, (3,3), activation='relu',name=\"L3\"),\n#     tf.keras.layers.MaxPooling2D(2,2),\n# #     # The fourth convolution\n# #     tf.keras.layers.Conv2D(128, (3,3), activation='relu',name=\"L4\"),\n# #     tf.keras.layers.MaxPooling2D(2,2),\n#     # Flatten the results to feed into a DNN\n#     tf.keras.layers.Flatten(),\n#     tf.keras.layers.Dropout(0.5),\n#     # 512 neuron hidden layer\n#     tf.keras.layers.Dense(512, activation='relu',name=\"dense1\" ),\n#     tf.keras.layers.Dense(14, activation='softmax')\n# ])\n\n# # Print the model summary\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-09T08:43:08.985049Z","iopub.execute_input":"2023-11-09T08:43:08.985337Z","iopub.status.idle":"2023-11-09T08:43:08.990012Z","shell.execute_reply.started":"2023-11-09T08:43:08.985311Z","shell.execute_reply":"2023-11-09T08:43:08.989121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Initialising the CNN\n# cnn = tf.keras.models.Sequential()\n\n# # Step 1 - Convolution\n# cnn.add(tf.keras.layers.Conv2D(filters=32,padding=\"same\",kernel_size=3, activation='relu', input_shape=[150,150, 3]))\n\n# # Step 2 - Pooling\n# cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n\n# # Adding a second convolutional layer\n# cnn.add(tf.keras.layers.Conv2D(filters=32,padding='same',kernel_size=3, activation='relu'))\n# cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n\n\n# # Adding a third convolutional layer\n# cnn.add(tf.keras.layers.Conv2D(filters=32,padding='same',kernel_size=3, activation='relu'))\n# cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n\n# # Step 3 - Flattening\n# cnn.add(tf.keras.layers.Flatten())\n\n# # Step 4 - Full Connection\n# cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n\n# # Step 5 - Output Layer\n# cnn.add(tf.keras.layers.Dense(units=4, activation='softmax')) ","metadata":{"execution":{"iopub.status.busy":"2023-11-09T08:43:08.991243Z","iopub.execute_input":"2023-11-09T08:43:08.991527Z","iopub.status.idle":"2023-11-09T08:43:09.005171Z","shell.execute_reply.started":"2023-11-09T08:43:08.991495Z","shell.execute_reply":"2023-11-09T08:43:09.004337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import tensorflow as tf\n\n# model = tf.keras.models.Sequential([\n#     # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n#     # This is the first convolution\n#     tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3),name=\"L1\"),\n#     tf.keras.layers.MaxPooling2D(2, 2),\n#     # The second convolution\n#     tf.keras.layers.Conv2D(32, (3,3), activation='relu',name=\"L2\"),\n#     tf.keras.layers.MaxPooling2D(2,2),\n#     # The third convolution\n#     tf.keras.layers.Conv2D(16, (3,3), activation='relu',name=\"L3\"),\n#     tf.keras.layers.MaxPooling2D(2,2),\n# #     # The fourth convolution\n# #     tf.keras.layers.Conv2D(128, (3,3), activation='relu',name=\"L4\"),\n# #     tf.keras.layers.MaxPooling2D(2,2),\n#     # Flatten the results to feed into a DNN\n#     tf.keras.layers.Flatten(),\n#     tf.keras.layers.Dropout(0.5),\n#     # 512 neuron hidden layer\n#     tf.keras.layers.Dense(512, activation='relu',name=\"dense1\" ),\n#     tf.keras.layers.Dense(14, activation='softmax')\n# ])\n\n# # Print the model summary\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-09T08:43:09.006254Z","iopub.execute_input":"2023-11-09T08:43:09.006582Z","iopub.status.idle":"2023-11-09T08:43:09.014440Z","shell.execute_reply.started":"2023-11-09T08:43:09.006554Z","shell.execute_reply":"2023-11-09T08:43:09.013586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import tensorflow as tf\n\n# model = tf.keras.models.Sequential([\n#     # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n#     # This is the first convolution\n#     tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3),name=\"L1\"),\n#     tf.keras.layers.MaxPooling2D(2, 2),\n#     # The second convolution\n#     tf.keras.layers.Conv2D(64, (3,3), activation='relu',name=\"L2\"),\n#     tf.keras.layers.MaxPooling2D(2,2),\n#     # The third convolution\n#     tf.keras.layers.Conv2D(256, (3,3), activation='relu',name=\"L3\"),\n#     tf.keras.layers.MaxPooling2D(2,2),\n# #     # The fourth convolution\n#     tf.keras.layers.Conv2D(512, (3,3), activation='relu',name=\"L4\"),\n#     tf.keras.layers.MaxPooling2D(2,2),\n#     # Flatten the results to feed into a DNN\n#     tf.keras.layers.Flatten(),\n#     tf.keras.layers.Dense(512, activation='relu',name=\"dense1\" ),\n# #     tf.keras.layers.BatchNormalization(),\n# #     tf.keras.layers.Dropout(0.25),\n#     # 512 neuron hidden layer\n# #     tf.keras.layers.Dense(128, activation='relu',name=\"dense2\" ),\n# #     tf.keras.layers.BatchNormalization(),\n# #     tf.keras.layers.Dropout(0.25),\n    \n#     tf.keras.layers.Dense(4, activation='softmax')\n# ])\n\n# # Print the model summary\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-09T08:43:09.017636Z","iopub.execute_input":"2023-11-09T08:43:09.017902Z","iopub.status.idle":"2023-11-09T08:43:09.027727Z","shell.execute_reply.started":"2023-11-09T08:43:09.017871Z","shell.execute_reply":"2023-11-09T08:43:09.026840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 1 ","metadata":{}},{"cell_type":"code","source":"# import tensorflow as tf\n# from tensorflow.keras.models import Sequential\n# from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPool2D, GlobalMaxPooling2D,Dropout\n\n\n\n# model = Sequential()\n\n# model.add(Conv2D(16 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (64,64,3), name=\"L1\")),\n# model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same')),\n# model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu',name=\"L2\")),\n# model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same')),\n# model.add(BatchNormalization()),\n# model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu',name=\"L3\")),\n# model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same')),\n# model.add(BatchNormalization()),\n# model.add(Dropout(0.2)),\n# model.add(Flatten()),\n# model.add(Dense(units = 128 , activation = 'relu',name=\"Dense1\")),\n# # model.add(Dense(units = 3 , activation = 'softmax'))\n\n\n# model.add(Dense(4, kernel_regularizer= tf.keras.regularizers.l2(0.01),activation = 'softmax'))\n# model.summary()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T08:43:09.029002Z","iopub.execute_input":"2023-11-09T08:43:09.029325Z","iopub.status.idle":"2023-11-09T08:43:09.040304Z","shell.execute_reply.started":"2023-11-09T08:43:09.029294Z","shell.execute_reply":"2023-11-09T08:43:09.039524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 2","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPool2D, GlobalMaxPooling2D,Dropout\n\n\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'valid' , activation = 'relu' , input_shape = (120,120,3), name=\"L1\")),\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'valid')),\nmodel.add(BatchNormalization()),\n# model.add(Dropout(0.1)),\n\n\nmodel.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'valid' , activation = 'relu',name=\"L2\")),\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'valid')),\nmodel.add(BatchNormalization()),\n# model.add(Dropout(0.2)),\n\n\nmodel.add(Conv2D(128, (3,3) , strides = 1 , padding = 'valid' , activation = 'relu',name=\"L3\")),\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'valid')),\nmodel.add(BatchNormalization()),\n# model.add(Dropout(0.3)),\n\n\nmodel.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'valid' , activation = 'leaky_relu',name=\"L4\")),\nmodel.add(MaxPool2D((2,2) , strides = 2 , padding = 'valid')),\nmodel.add(BatchNormalization()),\n# # # model.add(Dropout(0.4)),\n\n\n# model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'valid' , activation = 'leaky_relu',name=\"L5\")),\n# model.add(MaxPool2D((2,2) , strides = 2 , padding = 'valid')),\n# model.add(BatchNormalization()),\n# model.add(Conv2D(512 , (3,3) , strides = 1 , padding = 'valid' , activation = 'leaky_relu',name=\"L6\")),\n# model.add(MaxPool2D((2,2) , strides = 2 , padding = 'valid')),\n\n\n\nmodel.add(Flatten()),\nmodel.add(BatchNormalization()),\nmodel.add(Dropout(0.2)),\nmodel.add(Dense(units = 512 , activation = 'relu')),\n# model.add(Dense(units = 128 , activation = 'leaky_relu')),\n\n\n# Prohobitted\nmodel.add(Dense(1, kernel_regularizer= tf.keras.regularizers.l2(0.01),activation = 'sigmoid'))\n\n\nmodel.summary()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-11T18:14:47.369812Z","iopub.execute_input":"2024-02-11T18:14:47.370187Z","iopub.status.idle":"2024-02-11T18:14:47.586579Z","shell.execute_reply.started":"2024-02-11T18:14:47.370157Z","shell.execute_reply":"2024-02-11T18:14:47.585723Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n L1 (Conv2D)                 (None, 118, 118, 32)      896       \n                                                                 \n max_pooling2d_5 (MaxPoolin  (None, 59, 59, 32)        0         \n g2D)                                                            \n                                                                 \n batch_normalization_6 (Bat  (None, 59, 59, 32)        128       \n chNormalization)                                                \n                                                                 \n L2 (Conv2D)                 (None, 57, 57, 64)        18496     \n                                                                 \n max_pooling2d_6 (MaxPoolin  (None, 28, 28, 64)        0         \n g2D)                                                            \n                                                                 \n batch_normalization_7 (Bat  (None, 28, 28, 64)        256       \n chNormalization)                                                \n                                                                 \n L3 (Conv2D)                 (None, 26, 26, 128)       73856     \n                                                                 \n max_pooling2d_7 (MaxPoolin  (None, 13, 13, 128)       0         \n g2D)                                                            \n                                                                 \n batch_normalization_8 (Bat  (None, 13, 13, 128)       512       \n chNormalization)                                                \n                                                                 \n L4 (Conv2D)                 (None, 11, 11, 128)       147584    \n                                                                 \n max_pooling2d_8 (MaxPoolin  (None, 5, 5, 128)         0         \n g2D)                                                            \n                                                                 \n batch_normalization_9 (Bat  (None, 5, 5, 128)         512       \n chNormalization)                                                \n                                                                 \n flatten_1 (Flatten)         (None, 3200)              0         \n                                                                 \n batch_normalization_10 (Ba  (None, 3200)              12800     \n tchNormalization)                                               \n                                                                 \n dropout_1 (Dropout)         (None, 3200)              0         \n                                                                 \n dense_2 (Dense)             (None, 512)               1638912   \n                                                                 \n dense_3 (Dense)             (None, 1)                 513       \n                                                                 \n=================================================================\nTotal params: 1894465 (7.23 MB)\nTrainable params: 1887361 (7.20 MB)\nNon-trainable params: 7104 (27.75 KB)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"start = time.time()\n\n# Compiling the CNN  # Set the training parameters\n# model.compile(optimizer = 'adam',loss = 'categorical_crossentropy', metrics = ['accuracy'])\n# optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n#optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n\nmodel.compile(optimizer = optimizer ,loss = 'binary_crossentropy', metrics = ['accuracy'])\n# model.compile(optimizer = optimizer ,loss = 'squared_hinge', metrics = ['accuracy'])\n\n\n# Training the CNN on the Training set and evaluating it on the Test set\ncallbacks = myCallback()\nhistory = model.fit_generator( train_generator, \n                  validation_data = validation_generator, \n                  epochs = 100,\n                  callbacks=[callbacks],            \n#                   callbacks=[es],\n                  #steps_per_epoch=62,\n                  #validation_steps=6\n                 )\n\nend = time.time()\nelapsed = end - start\nprint(\"Total Time:\", elapsed)","metadata":{"execution":{"iopub.status.busy":"2024-02-11T18:15:09.657080Z","iopub.execute_input":"2024-02-11T18:15:09.657983Z","iopub.status.idle":"2024-02-11T19:43:34.717240Z","shell.execute_reply.started":"2024-02-11T18:15:09.657939Z","shell.execute_reply":"2024-02-11T19:43:34.716277Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_47/3636303729.py:15: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  history = model.fit_generator( train_generator,\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n301/301 [==============================] - 58s 178ms/step - loss: 0.6552 - accuracy: 0.8137 - val_loss: 0.6283 - val_accuracy: 0.6970\nEpoch 2/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.3936 - accuracy: 0.8525 - val_loss: 0.4534 - val_accuracy: 0.7970\nEpoch 3/100\n301/301 [==============================] - 53s 174ms/step - loss: 0.3227 - accuracy: 0.8666 - val_loss: 0.2612 - val_accuracy: 0.8940\nEpoch 4/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.3066 - accuracy: 0.8736 - val_loss: 0.6334 - val_accuracy: 0.6610\nEpoch 5/100\n301/301 [==============================] - 53s 176ms/step - loss: 0.2904 - accuracy: 0.8799 - val_loss: 0.2525 - val_accuracy: 0.8920\nEpoch 6/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.2902 - accuracy: 0.8792 - val_loss: 0.3865 - val_accuracy: 0.8280\nEpoch 7/100\n301/301 [==============================] - 53s 176ms/step - loss: 0.2829 - accuracy: 0.8826 - val_loss: 0.6540 - val_accuracy: 0.7390\nEpoch 8/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.2840 - accuracy: 0.8815 - val_loss: 0.5487 - val_accuracy: 0.7020\nEpoch 9/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.2795 - accuracy: 0.8863 - val_loss: 0.2436 - val_accuracy: 0.8890\nEpoch 10/100\n301/301 [==============================] - 53s 176ms/step - loss: 0.2740 - accuracy: 0.8894 - val_loss: 0.2776 - val_accuracy: 0.8910\nEpoch 11/100\n301/301 [==============================] - 53s 176ms/step - loss: 0.2671 - accuracy: 0.8879 - val_loss: 0.2917 - val_accuracy: 0.8670\nEpoch 12/100\n301/301 [==============================] - 52s 174ms/step - loss: 0.2662 - accuracy: 0.8914 - val_loss: 0.3015 - val_accuracy: 0.8580\nEpoch 13/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.2623 - accuracy: 0.8914 - val_loss: 0.2606 - val_accuracy: 0.9050\nEpoch 14/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.2549 - accuracy: 0.8964 - val_loss: 0.4231 - val_accuracy: 0.8050\nEpoch 15/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.2600 - accuracy: 0.8941 - val_loss: 0.2450 - val_accuracy: 0.9060\nEpoch 16/100\n301/301 [==============================] - 52s 174ms/step - loss: 0.2532 - accuracy: 0.8992 - val_loss: 0.2383 - val_accuracy: 0.9020\nEpoch 17/100\n301/301 [==============================] - 53s 174ms/step - loss: 0.2510 - accuracy: 0.8964 - val_loss: 0.3673 - val_accuracy: 0.8740\nEpoch 18/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.2430 - accuracy: 0.9022 - val_loss: 0.3151 - val_accuracy: 0.8800\nEpoch 19/100\n301/301 [==============================] - 53s 176ms/step - loss: 0.2396 - accuracy: 0.9050 - val_loss: 0.5513 - val_accuracy: 0.7780\nEpoch 20/100\n301/301 [==============================] - 53s 177ms/step - loss: 0.2475 - accuracy: 0.9004 - val_loss: 0.2561 - val_accuracy: 0.8950\nEpoch 21/100\n301/301 [==============================] - 53s 177ms/step - loss: 0.2386 - accuracy: 0.9009 - val_loss: 0.2813 - val_accuracy: 0.8900\nEpoch 22/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.2330 - accuracy: 0.9056 - val_loss: 0.2510 - val_accuracy: 0.8950\nEpoch 23/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.2359 - accuracy: 0.9071 - val_loss: 0.2180 - val_accuracy: 0.9100\nEpoch 24/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.2286 - accuracy: 0.9088 - val_loss: 0.2512 - val_accuracy: 0.9080\nEpoch 25/100\n301/301 [==============================] - 53s 176ms/step - loss: 0.2280 - accuracy: 0.9091 - val_loss: 0.2352 - val_accuracy: 0.8990\nEpoch 26/100\n301/301 [==============================] - 54s 179ms/step - loss: 0.2241 - accuracy: 0.9093 - val_loss: 0.2840 - val_accuracy: 0.8900\nEpoch 27/100\n301/301 [==============================] - 54s 178ms/step - loss: 0.2212 - accuracy: 0.9113 - val_loss: 0.2500 - val_accuracy: 0.9030\nEpoch 28/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.2219 - accuracy: 0.9137 - val_loss: 0.2204 - val_accuracy: 0.9010\nEpoch 29/100\n301/301 [==============================] - 52s 174ms/step - loss: 0.2210 - accuracy: 0.9108 - val_loss: 0.2451 - val_accuracy: 0.9030\nEpoch 30/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.2242 - accuracy: 0.9124 - val_loss: 0.5308 - val_accuracy: 0.8220\nEpoch 31/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.2101 - accuracy: 0.9181 - val_loss: 0.2286 - val_accuracy: 0.9050\nEpoch 32/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.2159 - accuracy: 0.9109 - val_loss: 0.2632 - val_accuracy: 0.8910\nEpoch 33/100\n301/301 [==============================] - 53s 176ms/step - loss: 0.2223 - accuracy: 0.9118 - val_loss: 0.2527 - val_accuracy: 0.8960\nEpoch 34/100\n301/301 [==============================] - 53s 176ms/step - loss: 0.2172 - accuracy: 0.9117 - val_loss: 0.2248 - val_accuracy: 0.8980\nEpoch 35/100\n301/301 [==============================] - 53s 176ms/step - loss: 0.2121 - accuracy: 0.9139 - val_loss: 0.5476 - val_accuracy: 0.8140\nEpoch 36/100\n301/301 [==============================] - 52s 174ms/step - loss: 0.2075 - accuracy: 0.9123 - val_loss: 0.2330 - val_accuracy: 0.9100\nEpoch 37/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.2088 - accuracy: 0.9157 - val_loss: 0.2384 - val_accuracy: 0.8910\nEpoch 38/100\n301/301 [==============================] - 53s 176ms/step - loss: 0.2040 - accuracy: 0.9179 - val_loss: 0.2159 - val_accuracy: 0.9020\nEpoch 39/100\n301/301 [==============================] - 52s 174ms/step - loss: 0.2050 - accuracy: 0.9179 - val_loss: 0.3115 - val_accuracy: 0.8830\nEpoch 40/100\n301/301 [==============================] - 54s 178ms/step - loss: 0.2057 - accuracy: 0.9211 - val_loss: 0.2225 - val_accuracy: 0.9050\nEpoch 41/100\n301/301 [==============================] - 53s 177ms/step - loss: 0.2094 - accuracy: 0.9178 - val_loss: 0.2217 - val_accuracy: 0.9090\nEpoch 42/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.2011 - accuracy: 0.9156 - val_loss: 0.2954 - val_accuracy: 0.8880\nEpoch 43/100\n301/301 [==============================] - 53s 176ms/step - loss: 0.2024 - accuracy: 0.9168 - val_loss: 0.2238 - val_accuracy: 0.9090\nEpoch 44/100\n301/301 [==============================] - 53s 174ms/step - loss: 0.1995 - accuracy: 0.9194 - val_loss: 0.2406 - val_accuracy: 0.9060\nEpoch 45/100\n301/301 [==============================] - 53s 176ms/step - loss: 0.2021 - accuracy: 0.9171 - val_loss: 0.2154 - val_accuracy: 0.9080\nEpoch 46/100\n301/301 [==============================] - 52s 174ms/step - loss: 0.1978 - accuracy: 0.9208 - val_loss: 0.2533 - val_accuracy: 0.9000\nEpoch 47/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.2024 - accuracy: 0.9172 - val_loss: 0.2120 - val_accuracy: 0.9110\nEpoch 48/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.1980 - accuracy: 0.9192 - val_loss: 0.2080 - val_accuracy: 0.9110\nEpoch 49/100\n301/301 [==============================] - 52s 174ms/step - loss: 0.1918 - accuracy: 0.9211 - val_loss: 0.2145 - val_accuracy: 0.9060\nEpoch 50/100\n301/301 [==============================] - 54s 180ms/step - loss: 0.1937 - accuracy: 0.9212 - val_loss: 0.2652 - val_accuracy: 0.8810\nEpoch 51/100\n301/301 [==============================] - 54s 179ms/step - loss: 0.1930 - accuracy: 0.9217 - val_loss: 2.6548 - val_accuracy: 0.6320\nEpoch 52/100\n301/301 [==============================] - 54s 178ms/step - loss: 0.1923 - accuracy: 0.9237 - val_loss: 0.3355 - val_accuracy: 0.8740\nEpoch 53/100\n301/301 [==============================] - 53s 177ms/step - loss: 0.1883 - accuracy: 0.9244 - val_loss: 0.2230 - val_accuracy: 0.9020\nEpoch 54/100\n301/301 [==============================] - 54s 178ms/step - loss: 0.1852 - accuracy: 0.9237 - val_loss: 0.2941 - val_accuracy: 0.8900\nEpoch 55/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.1901 - accuracy: 0.9233 - val_loss: 0.2404 - val_accuracy: 0.9000\nEpoch 56/100\n301/301 [==============================] - 53s 177ms/step - loss: 0.1976 - accuracy: 0.9209 - val_loss: 0.2263 - val_accuracy: 0.9070\nEpoch 57/100\n301/301 [==============================] - 53s 177ms/step - loss: 0.1873 - accuracy: 0.9256 - val_loss: 0.2327 - val_accuracy: 0.9060\nEpoch 58/100\n301/301 [==============================] - 53s 177ms/step - loss: 0.1937 - accuracy: 0.9230 - val_loss: 0.2419 - val_accuracy: 0.9030\nEpoch 59/100\n301/301 [==============================] - 53s 176ms/step - loss: 0.1853 - accuracy: 0.9246 - val_loss: 0.2673 - val_accuracy: 0.8970\nEpoch 60/100\n301/301 [==============================] - 54s 179ms/step - loss: 0.1881 - accuracy: 0.9240 - val_loss: 0.2801 - val_accuracy: 0.9110\nEpoch 61/100\n301/301 [==============================] - 53s 176ms/step - loss: 0.1849 - accuracy: 0.9271 - val_loss: 0.2185 - val_accuracy: 0.9060\nEpoch 62/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.1855 - accuracy: 0.9252 - val_loss: 0.4056 - val_accuracy: 0.8290\nEpoch 63/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.1834 - accuracy: 0.9281 - val_loss: 0.2531 - val_accuracy: 0.8930\nEpoch 64/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.1803 - accuracy: 0.9271 - val_loss: 0.4070 - val_accuracy: 0.8470\nEpoch 65/100\n301/301 [==============================] - 53s 177ms/step - loss: 0.1823 - accuracy: 0.9233 - val_loss: 0.2747 - val_accuracy: 0.8920\nEpoch 66/100\n301/301 [==============================] - 53s 177ms/step - loss: 0.1754 - accuracy: 0.9277 - val_loss: 0.2288 - val_accuracy: 0.9010\nEpoch 67/100\n301/301 [==============================] - 53s 178ms/step - loss: 0.1819 - accuracy: 0.9259 - val_loss: 0.2220 - val_accuracy: 0.9010\nEpoch 68/100\n301/301 [==============================] - 53s 177ms/step - loss: 0.1790 - accuracy: 0.9291 - val_loss: 0.2371 - val_accuracy: 0.9070\nEpoch 69/100\n301/301 [==============================] - 53s 177ms/step - loss: 0.1793 - accuracy: 0.9281 - val_loss: 0.3037 - val_accuracy: 0.8970\nEpoch 70/100\n301/301 [==============================] - 53s 177ms/step - loss: 0.1753 - accuracy: 0.9291 - val_loss: 0.2665 - val_accuracy: 0.8960\nEpoch 71/100\n301/301 [==============================] - 53s 176ms/step - loss: 0.1775 - accuracy: 0.9285 - val_loss: 0.2293 - val_accuracy: 0.9050\nEpoch 72/100\n301/301 [==============================] - 53s 176ms/step - loss: 0.1755 - accuracy: 0.9306 - val_loss: 0.2602 - val_accuracy: 0.8890\nEpoch 73/100\n301/301 [==============================] - 53s 177ms/step - loss: 0.1835 - accuracy: 0.9262 - val_loss: 0.2276 - val_accuracy: 0.9020\nEpoch 74/100\n301/301 [==============================] - 53s 176ms/step - loss: 0.1713 - accuracy: 0.9298 - val_loss: 0.2512 - val_accuracy: 0.9010\nEpoch 75/100\n301/301 [==============================] - 53s 176ms/step - loss: 0.1815 - accuracy: 0.9249 - val_loss: 0.2603 - val_accuracy: 0.9040\nEpoch 76/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.1754 - accuracy: 0.9308 - val_loss: 0.2756 - val_accuracy: 0.9050\nEpoch 77/100\n301/301 [==============================] - 54s 179ms/step - loss: 0.1716 - accuracy: 0.9297 - val_loss: 0.2836 - val_accuracy: 0.8990\nEpoch 78/100\n301/301 [==============================] - 53s 177ms/step - loss: 0.1739 - accuracy: 0.9289 - val_loss: 0.2777 - val_accuracy: 0.9060\nEpoch 79/100\n301/301 [==============================] - 52s 174ms/step - loss: 0.1783 - accuracy: 0.9285 - val_loss: 0.2575 - val_accuracy: 0.9030\nEpoch 80/100\n301/301 [==============================] - 53s 177ms/step - loss: 0.1747 - accuracy: 0.9292 - val_loss: 0.2408 - val_accuracy: 0.9080\nEpoch 81/100\n301/301 [==============================] - 53s 176ms/step - loss: 0.1736 - accuracy: 0.9280 - val_loss: 0.2274 - val_accuracy: 0.9040\nEpoch 82/100\n301/301 [==============================] - 53s 176ms/step - loss: 0.1734 - accuracy: 0.9289 - val_loss: 0.2546 - val_accuracy: 0.8940\nEpoch 83/100\n301/301 [==============================] - 54s 180ms/step - loss: 0.1697 - accuracy: 0.9315 - val_loss: 0.4996 - val_accuracy: 0.8340\nEpoch 84/100\n301/301 [==============================] - 54s 178ms/step - loss: 0.1761 - accuracy: 0.9318 - val_loss: 0.2552 - val_accuracy: 0.9090\nEpoch 85/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.1726 - accuracy: 0.9306 - val_loss: 0.2312 - val_accuracy: 0.9100\nEpoch 86/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.1687 - accuracy: 0.9312 - val_loss: 0.3742 - val_accuracy: 0.8820\nEpoch 87/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.1718 - accuracy: 0.9320 - val_loss: 0.2928 - val_accuracy: 0.8920\nEpoch 88/100\n301/301 [==============================] - 52s 174ms/step - loss: 0.1695 - accuracy: 0.9301 - val_loss: 0.2367 - val_accuracy: 0.9050\nEpoch 89/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.1743 - accuracy: 0.9274 - val_loss: 0.2903 - val_accuracy: 0.8920\nEpoch 90/100\n301/301 [==============================] - 54s 180ms/step - loss: 0.1728 - accuracy: 0.9294 - val_loss: 0.4712 - val_accuracy: 0.8310\nEpoch 91/100\n301/301 [==============================] - 53s 177ms/step - loss: 0.1694 - accuracy: 0.9328 - val_loss: 0.3259 - val_accuracy: 0.8890\nEpoch 92/100\n301/301 [==============================] - 53s 176ms/step - loss: 0.1736 - accuracy: 0.9322 - val_loss: 0.2627 - val_accuracy: 0.8950\nEpoch 93/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.1711 - accuracy: 0.9298 - val_loss: 0.2737 - val_accuracy: 0.8920\nEpoch 94/100\n301/301 [==============================] - 53s 177ms/step - loss: 0.1668 - accuracy: 0.9331 - val_loss: 0.2783 - val_accuracy: 0.9080\nEpoch 95/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.1713 - accuracy: 0.9320 - val_loss: 0.4113 - val_accuracy: 0.8860\nEpoch 96/100\n301/301 [==============================] - 52s 172ms/step - loss: 0.1688 - accuracy: 0.9328 - val_loss: 0.3609 - val_accuracy: 0.8870\nEpoch 97/100\n301/301 [==============================] - 53s 176ms/step - loss: 0.1686 - accuracy: 0.9298 - val_loss: 0.4935 - val_accuracy: 0.8520\nEpoch 98/100\n301/301 [==============================] - 54s 178ms/step - loss: 0.1690 - accuracy: 0.9327 - val_loss: 0.4422 - val_accuracy: 0.8640\nEpoch 99/100\n301/301 [==============================] - 54s 178ms/step - loss: 0.1647 - accuracy: 0.9316 - val_loss: 0.2322 - val_accuracy: 0.9180\nEpoch 100/100\n301/301 [==============================] - 53s 175ms/step - loss: 0.1686 - accuracy: 0.9322 - val_loss: 0.2198 - val_accuracy: 0.9040\nTotal Time: 5305.053160429001\n","output_type":"stream"}]},{"cell_type":"code","source":"\nmodel.save('V2.h5')","metadata":{"execution":{"iopub.status.busy":"2023-11-09T08:45:10.504679Z","iopub.execute_input":"2023-11-09T08:45:10.505343Z","iopub.status.idle":"2023-11-09T08:45:10.571472Z","shell.execute_reply.started":"2023-11-09T08:45:10.505297Z","shell.execute_reply":"2023-11-09T08:45:10.570640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Input, Lambda, Dense, Flatten\nfrom keras.models import Model\nfrom keras.applications.vgg19 import VGG19\nfrom keras.applications.vgg19 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nimport numpy as np\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport tensorflow as tf","metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2023-11-09T08:45:10.572549Z","iopub.execute_input":"2023-11-09T08:45:10.572808Z","iopub.status.idle":"2023-11-09T08:45:10.578978Z","shell.execute_reply.started":"2023-11-09T08:45:10.572784Z","shell.execute_reply":"2023-11-09T08:45:10.577932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# accuracies\nplt.figure(figsize=(10,4))\nplt.plot(history.history['accuracy'], label='train acc')\nplt.plot(history.history['val_accuracy'], label='val acc')\nplt.ylabel('Accuracy')\nplt.xlabel('No. of Iteration')\nplt.legend()\nplt.savefig('Accuracy')\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T08:45:10.580217Z","iopub.execute_input":"2023-11-09T08:45:10.580503Z","iopub.status.idle":"2023-11-09T08:45:10.969642Z","shell.execute_reply.started":"2023-11-09T08:45:10.580479Z","shell.execute_reply":"2023-11-09T08:45:10.968595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc= history.history['accuracy']\nval_acc= history.history['val_accuracy']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-09T08:45:10.970882Z","iopub.execute_input":"2023-11-09T08:45:10.971282Z","iopub.status.idle":"2023-11-09T08:45:11.212474Z","shell.execute_reply.started":"2023-11-09T08:45:10.971245Z","shell.execute_reply":"2023-11-09T08:45:11.211626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Confution Matrix and Classification Report\n!pip install mlxtend\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport numpy as np\nY_pred = model.predict_generator(validation_generator, 608 //32+1)  #pred_prob\n\ny_pred = np.argmax(Y_pred, axis=1)#orig_test_labels1\nprint('Confusion Matrix')\nprint(confusion_matrix(validation_generator.classes, y_pred))\nprint('Classification Report')\ntarget_names = ['Black_Measles', 'Black_rot', 'Leaf_blight','healthy']\n\nprint(classification_report(validation_generator.classes, y_pred, target_names=target_names  ))   #validation_generator.classes =orig_test_labels1\nclass_names = ['Black_Measles', 'Black_rot', 'Leaf_blight','healthy']\nmat= confusion_matrix(validation_generator.classes, y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-11-09T08:45:11.213496Z","iopub.execute_input":"2023-11-09T08:45:11.213753Z","iopub.status.idle":"2023-11-09T08:45:26.049930Z","shell.execute_reply.started":"2023-11-09T08:45:11.213730Z","shell.execute_reply":"2023-11-09T08:45:26.048756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn import metrics\n# import matplotlib.pyplot as plt\n# from itertools import cycle\n# from scipy import interp\n\n# score = metrics.accuracy_score(orig_test_labels1, pred)\n# print(\"Accuracy score: {}\".format(score))\n# pred_prob = final_model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-11-09T08:45:26.051366Z","iopub.execute_input":"2023-11-09T08:45:26.051681Z","iopub.status.idle":"2023-11-09T08:45:26.056037Z","shell.execute_reply.started":"2023-11-09T08:45:26.051650Z","shell.execute_reply":"2023-11-09T08:45:26.055073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import math\nnumber_of_examples = len(validation_generator.filenames)\nnumber_of_generator_calls = math.ceil(number_of_examples / (1.0 * 32)) \n# 1.0 above is to skip integer division\n\ntest_labels = []\ntest_images = []\n\nfor i in range(0,int(number_of_generator_calls)):\n    test_labels.extend(np.array(validation_generator[i][1]))\n\nfor i in range(0,int(number_of_generator_calls)):\n    test_images.extend(np.array(validation_generator[i][0]))\n    %matplotlib inline\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport matplotlib.pyplot as plt\npredictions = model.predict_generator(validation_generator)\nnew_labels = []\nfor i in range(0,608):\n  new_labels.append(np.argmax(predictions[i]))\nnewtest_labels = []\nfor i in range(0,608):\n  newtest_labels.append(np.argmax(test_labels[i]))\ncm = confusion_matrix(y_true=newtest_labels, y_pred=new_labels)","metadata":{"execution":{"iopub.status.busy":"2023-11-09T08:45:26.057590Z","iopub.execute_input":"2023-11-09T08:45:26.058008Z","iopub.status.idle":"2023-11-09T08:45:28.793921Z","shell.execute_reply.started":"2023-11-09T08:45:26.057937Z","shell.execute_reply":"2023-11-09T08:45:28.793092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(test_images)","metadata":{"execution":{"iopub.status.busy":"2023-11-09T08:45:28.795025Z","iopub.execute_input":"2023-11-09T08:45:28.795316Z","iopub.status.idle":"2023-11-09T08:45:28.801605Z","shell.execute_reply.started":"2023-11-09T08:45:28.795291Z","shell.execute_reply":"2023-11-09T08:45:28.800552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from sklearn import metrics\nimport matplotlib.pyplot as plt\nfrom itertools import cycle\nfrom scipy import interp\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, auc\nscore = metrics.accuracy_score(newtest_labels, new_labels)\nprint(\"Accuracy score: {}\".format(score))\npred_prob = model.predict_generator(validation_generator)\n\nc = roc_auc_score(newtest_labels, pred_prob, multi_class='ovo')\nprint(\"AUC:\", c)\n# Compute ROC curve and ROC area for each class\nfpr = {}\ntpr = {}\nroc_auc = {}\nthresh = {}\nlw = 2\nprecision = {}\nrecall = {}\nfor i in range(4):  # here need to be modified \n    fpr[i], tpr[i], thresh[i] = roc_curve(newtest_labels, pred_prob[:, i], pos_label=i)\n    precision[i], recall[i], _ = roc_curve(newtest_labels, pred_prob[:, i], pos_label=i)\n    roc_auc[i] = auc(fpr[i], tpr[i])\n    plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n\n\n\n\nplt.xlabel(\"recall\")\nplt.ylabel(\"precision\")\nplt.legend(loc=\"best\")\nplt.title(\"precision vs. recall curve\")\nplt.savefig('PR_CURVE')\nplt.show()\n\nn_classes = 4\n\n# First aggregate all false positive rates\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\n# Then interpolate all ROC curves at this points\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\n# Finally average it and compute AUC\nmean_tpr /= n_classes\n\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n# Plot all ROC curves\nplt.figure()\n\ncolors = cycle(['green', 'black', 'red', 'yellow' ])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw, label='ROC curve of class {0} (area = {1:0.4f})'\n                                                       ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Some extension of Receiver operating characteristic to multi-class')\nplt.legend(loc=\"lower right\")\nplt.savefig('ROC')\nplt.show()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T08:45:28.803374Z","iopub.execute_input":"2023-11-09T08:45:28.804082Z","iopub.status.idle":"2023-11-09T08:45:30.696659Z","shell.execute_reply.started":"2023-11-09T08:45:28.804048Z","shell.execute_reply":"2023-11-09T08:45:30.695777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Display\nfrom IPython.display import Image, display\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\n\nlast_conv_layer_name = \"L3\"\nimg_path = \"/kaggle/input/grape-cnnsvm/Grape/Testing/healthy/0f8906e9-86e1-49f8-aea0-3e887924799d___Mt.N.V_HL 9012.JPG\"\n\nimg_size = (120, 120)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T08:45:30.697986Z","iopub.execute_input":"2023-11-09T08:45:30.698336Z","iopub.status.idle":"2023-11-09T08:45:30.704399Z","shell.execute_reply.started":"2023-11-09T08:45:30.698303Z","shell.execute_reply":"2023-11-09T08:45:30.703298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_img_array(img_path, size):\n    # `img` is a PIL image of size 299x299\n    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n    # `array` is a float32 Numpy array of shape (299, 299, 3)\n    array = keras.preprocessing.image.img_to_array(img)\n    # We add a dimension to transform our array into a \"batch\"\n    # of size (1, 299, 299, 3)\n    array = np.expand_dims(array, axis=0)\n    return array\n\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    # First, we create a model that maps the input image to the activations\n    # of the last conv layer as well as the output predictions\n    grad_model = tf.keras.models.Model(\n        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n\n    # Then, we compute the gradient of the top predicted class for our input image\n    # with respect to the activations of the last conv layer\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    # This is the gradient of the output neuron (top predicted or chosen)\n    # with regard to the output feature map of the last conv layer\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n\n    # This is a vector where each entry is the mean intensity of the gradient\n    # over a specific feature map channel\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # We multiply each channel in the feature map array\n    # by \"how important this channel is\" with regard to the top predicted class\n    # then sum all the channels to obtain the heatmap class activation\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n\n    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()","metadata":{"execution":{"iopub.status.busy":"2023-11-09T08:45:30.705982Z","iopub.execute_input":"2023-11-09T08:45:30.706328Z","iopub.status.idle":"2023-11-09T08:45:30.716221Z","shell.execute_reply.started":"2023-11-09T08:45:30.706297Z","shell.execute_reply":"2023-11-09T08:45:30.715195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare image\n\nimg_array = preprocess_input(get_img_array(img_path, size=img_size))\nmodel.layers[-1].activation = None\npreds = model.predict(img_array)\n\n# Generate class activation heatmap\nheatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n\n# Display heatmap\nplt.matshow(heatmap)\nplt.savefig('Heatmap_Healthy')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T08:45:30.720896Z","iopub.execute_input":"2023-11-09T08:45:30.721202Z","iopub.status.idle":"2023-11-09T08:45:31.606931Z","shell.execute_reply.started":"2023-11-09T08:45:30.721178Z","shell.execute_reply":"2023-11-09T08:45:31.605962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cam = plt.imread(img_path)\ndef save_and_display_gradcam(img_path, heatmap, cam_path=\"Superimposed_Healthy.jpg\", alpha=0.4):\n    # Load the original image\n    img = keras.preprocessing.image.load_img(img_path)\n    img = keras.preprocessing.image.img_to_array(img)\n\n    # Rescale heatmap to a range 0-255\n    heatmap = np.uint8(255 * heatmap)\n\n    # Use jet colormap to colorize heatmap\n    jet = cm.get_cmap(\"jet\")\n\n    # Use RGB values of the colormap\n    jet_colors = jet(np.arange(256))[:, :3]\n    jet_heatmap = jet_colors[heatmap]\n\n    # Create an image with RGB colorized heatmap\n    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n\n    # Superimpose the heatmap on original image\n    superimposed_img = jet_heatmap * alpha + img\n    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n\n    # Save the superimposed image\n    superimposed_img.save(cam_path)\n\n    # Display Grad CAM\n    display(Image(cam_path))\n\n\nsave_and_display_gradcam(img_path, heatmap)","metadata":{"execution":{"iopub.status.busy":"2023-11-09T08:45:31.608274Z","iopub.execute_input":"2023-11-09T08:45:31.608644Z","iopub.status.idle":"2023-11-09T08:45:31.628940Z","shell.execute_reply.started":"2023-11-09T08:45:31.608607Z","shell.execute_reply":"2023-11-09T08:45:31.627966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nnumber_of_examples = len(validation_generator.filenames)\nnumber_of_generator_calls = math.ceil(number_of_examples / (1.0 * 32)) \n# 1.0 above is to skip integer division\n\ntest_labels = []\ntest_images = []\n\nfor i in range(0,int(number_of_generator_calls)):\n    test_labels.extend(np.array(validation_generator[i][1]))\n\nfor i in range(0,int(number_of_generator_calls)):\n    test_images.extend(np.array(validation_generator[i][0]))\n    %matplotlib inline\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport matplotlib.pyplot as plt\npredictions = model.predict_generator(validation_generator)\nnew_labels = []\nfor i in range(0,608):\n  new_labels.append(np.argmax(predictions[i]))\nnewtest_labels = []\nfor i in range(0,608):\n  newtest_labels.append(np.argmax(test_labels[i]))\ncm = confusion_matrix(y_true=newtest_labels, y_pred=new_labels)","metadata":{"execution":{"iopub.status.busy":"2023-11-09T08:45:31.630253Z","iopub.execute_input":"2023-11-09T08:45:31.631014Z","iopub.status.idle":"2023-11-09T08:45:34.232996Z","shell.execute_reply.started":"2023-11-09T08:45:31.630979Z","shell.execute_reply":"2023-11-09T08:45:34.232054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                        normalize=False,\n                        title='Confusion matrix',\n                        cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting normalize=True.\n    \"\"\"\n    plt.figure(figsize=(10,10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    # plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n   ","metadata":{"execution":{"iopub.status.busy":"2023-11-09T08:45:34.234245Z","iopub.execute_input":"2023-11-09T08:45:34.234532Z","iopub.status.idle":"2023-11-09T08:45:34.244111Z","shell.execute_reply.started":"2023-11-09T08:45:34.234509Z","shell.execute_reply":"2023-11-09T08:45:34.242921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm_plot_labels =['Black_Rot', 'Esca', 'Leaf_Blight','healthy']\n# cm_plot_labels = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13']\nplot_confusion_matrix(cm=cm,classes=cm_plot_labels, title='Confusion Matrix'  )\nplt.savefig('ConfusionMatrix')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-09T08:45:34.245204Z","iopub.execute_input":"2023-11-09T08:45:34.245479Z","iopub.status.idle":"2023-11-09T08:45:34.805469Z","shell.execute_reply.started":"2023-11-09T08:45:34.245455Z","shell.execute_reply":"2023-11-09T08:45:34.804514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}